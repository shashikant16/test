{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_Trans_Dist.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPdhRCWrl8Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_-sHSC0V4OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for Saving the model\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AQVsNRMl9sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip '/content/drive/My Drive/TEST_DATASET.zip' -d '/content/drive/My Drive'\n",
        "# !unzip '/content/drive/My Drive/test_data_2.zip' -d '/content/drive/My Drive'\n",
        "\n",
        "\n",
        "# /content/drive/My Drive/TRAIN_DATASET.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI1oXZ1rmMF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = \"/content/drive/My Drive/TRAIN_DATASET\"\n",
        "TEST_DIR = \"/content/drive/My Drive/TEST_DATASET\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icE9ZvdqmTEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wpj6OH2mZOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 400\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "# epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "    \n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "    \n",
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "    \n",
        "# Flatten the output layer to 1 dimension\n",
        "x = GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Q7GG94v0Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights('/content/gdrive/My Drive/MyCNN/epochs:047-val_acc:0.905.hdf5') /content/drive/My Drive/checkpoints #epochs:022-accuracy:0.859.hdf5\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/checkpoints/epochs:022-accuracy:0.859.hdf5')  #/content/drive/My Drive/checkpoints #epochs:022-accuracy:0.859.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2k8nBWXmcy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY1l15ZsnO09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "filenames = os.listdir(\"/content/drive/My Drive/TRAIN_DATASET\")\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Transmission':\n",
        "        categories.append(1)\n",
        "    elif category == 'trans_and_dist':\n",
        "        categories.append(2)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jii-7Amhn2Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[5000:5010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMbySSMammPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFbwrhMTmnt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RucHI_vmmpYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]\n",
        "batch_size=15\n",
        "\n",
        "total_train,total_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdcM7TJCmrc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SIZE = len([name for name in os.listdir(TRAIN_DIR)])\n",
        "TEST_SIZE = len([name for name in os.listdir(TEST_DIR)])\n",
        "print(\"Number of training images:\", TRAIN_SIZE)\n",
        "print(\"Number of test images:\", TEST_SIZE)\n",
        "\n",
        "VALID_FRACTION = 0.2\n",
        "BATCH_SIZE = 32\n",
        "# EPOCHS = 30\n",
        "import tensorflow as tf\n",
        "IMAGE_WIDTH = IMAGE_HEIGHT = 250\n",
        "\n",
        "# creating df with train labels\n",
        "train_filenames = os.listdir(TRAIN_DIR)\n",
        "train_labels = []\n",
        "for filename in train_filenames:\n",
        "    label = filename.split('.')[0]\n",
        "    train_labels.append(label)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'id': train_filenames,\n",
        "    'label': train_labels\n",
        "})\n",
        "\n",
        "\n",
        "# splitting to train & valid\n",
        "train_df, valid_df = train_test_split(train_df, test_size=VALID_FRACTION)\n",
        "\n",
        "# augmentation settings, for now just normalizing\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(    \n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    rescale=1./255.,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "# not doing any data augmentation on validation test set\n",
        "valid_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "# creating train and valid generators (not using valid_split to avoid doing data augmentation on validation set)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    TRAIN_DIR, \n",
        "    x_col='id',\n",
        "    y_col='label',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(\n",
        "    valid_df, \n",
        "    TRAIN_DIR, \n",
        "    x_col='id',\n",
        "    y_col='label',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coAqfTyrvcOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCxusQPZmtNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQCQXd6Nmu7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath=\"/content/drive/My Drive/checkpoints/epochs:{epoch:03d}-accuracy:{accuracy:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orPq4vrWmwmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 35\n",
        "# training\n",
        "history = model.fit(train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    steps_per_epoch= round(TRAIN_SIZE*(1.-VALID_FRACTION)/BATCH_SIZE),\n",
        "    validation_steps= round(TRAIN_SIZE*VALID_FRACTION/BATCH_SIZE),\n",
        "    epochs= EPOCHS, \n",
        "    initial_epoch = 23,\n",
        "    callbacks=[callbacks_list],\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1YJYiAHmyE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('colab_VGG16_TD2.h5')\n",
        "model_file = drive.CreateFile({'Vision_1' : 'colab_VGG16_TD2.h5'})\n",
        "model_file.SetContentFile('colab_VGG16_TD2.h5')\n",
        "model_file.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu3nd9RmJOzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "IMAGE_WIDTH = IMAGE_HEIGHT = 250\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "TEST_DIR = \"/content/drive/My Drive/TEST_DATASET\"\n",
        "TEST_SIZE = len([name for name in os.listdir(TEST_DIR)])\n",
        "\n",
        "\n",
        "\n",
        "test_filenames = os.listdir(TEST_DIR)\n",
        "test_df = pd.DataFrame({\n",
        "    'id': test_filenames\n",
        "})\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df, \n",
        "    TEST_DIR, \n",
        "    x_col='id',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjooqRIjJIAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict_generator(test_generator, steps=np.ceil(TEST_SIZE/BATCH_SIZE))\n",
        "test_df['category'] = np.argmax(predict, axis=-1)\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)\n",
        "test_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEw2Cx6xWJ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3 Writing the output\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "fontScale = 2\n",
        "thickness = 2\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "sample_test = test_df.head(22)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(50, 50)) #12, 24)\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['id']\n",
        "    category = row['category']\n",
        "    img = cv2.imread(\"/content/drive/My Drive/TEST_DATASET/\"+filename)\n",
        "    img = cv2.resize(img, (480,640))\n",
        "    cv2.putText(img, category,(30, 50),font, fontScale, (0,255,0),thickness,True)\n",
        "    output_file_path = '/content/drive/My Drive/output2/' + filename\n",
        "    cv2.imwrite(output_file_path,img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GXSg6jVHsDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(30, 30)) #12, 24)\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['id']\n",
        "    category = row['category']\n",
        "    img = load_img(\"/content/drive/My Drive/TEST_DATASET/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM7p0xh-JgBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}